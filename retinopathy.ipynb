{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "retinopathy.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "unOg-rJfrC3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsEifWUsrC3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=np.fromfile('train.dat',dtype='uint8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft5NLJkurC4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lab=np.fromfile('dia.dat',dtype='int32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B16p2Y_grC4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lab=lab.reshape(3662,5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIqHu4m-rC4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lab1=np.where(lab==1065353216,1,lab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu5ulw4nrC5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d1=data.reshape(3662,1600,2400,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPCvJGwKrC5q",
        "colab_type": "code",
        "colab": {},
        "outputId": "89d719ae-e803-4f07-c5ff-cb7da89b05d9"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, LeakyReLU\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "\n",
        "batch_size = 32\n",
        "num_classes = 5\n",
        "epochs = 100\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "# save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "# model_name = 'keras_cifar10_trained_model.h5'\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# print('x_train shape:', x_train.shape)\n",
        "# print(x_train.shape[:1], 'train samples')\n",
        "# print(x_test.shape[:1], 'test samples')\n",
        "\n",
        "# y_train=y_train[:41]\n",
        "# y_test=y_test[41:50]\n",
        "# # Convert class vectors to binary class matrices.\n",
        "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "# y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Conv2D(64, (3, 3), padding='same',\n",
        "#                  input_shape=x_train.shape[1:]))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(BatchNormalization(momentum=0.8))\n",
        "# # model.add(Activation('relu'))\n",
        "# model.add(LeakyReLU(alpha=0.2))\n",
        "# model.add(Conv2D(32, (3, 3)))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(BatchNormalization(momentum=0.8))\n",
        "# model.add(LeakyReLU(alpha=0.2))\n",
        "# # model.add(Activation('relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Dropout(0.25))\n",
        "\n",
        "# model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(BatchNormalization(momentum=0.8))\n",
        "# model.add(LeakyReLU(alpha=0.2))\n",
        "# # model.add(Activation('relu'))\n",
        "# model.add(Conv2D(64, (3, 3)))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(BatchNormalization(momentum=0.8))\n",
        "# model.add(LeakyReLU(alpha=0.2))\n",
        "# # model.add(Activation('relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# model.add(Dropout(0.25))\n",
        "\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(512))\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(num_classes))\n",
        "# model.add(Activation('softmax'))\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "# opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# # Let's train the model using RMSprop\n",
        "# model.compile(loss='categorical_crossentropy',\n",
        "#               optimizer=opt,\n",
        "#               metrics=['accuracy'])\n",
        "x_train=d1[:2928]\n",
        "x_test=d1[2928:]\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "# y_train=x_train\n",
        "# y_test=x_test\n",
        "y_train=lab[:2928]\n",
        "y_test=lab[2928:]\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "#     model.fit(x_train, y_train,\n",
        "#               batch_size=batch_size,\n",
        "#               epochs=epochs,\n",
        "#               validation_data=(x_test, y_test),\n",
        "#               shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "#     datagen.fit(x_train)\n",
        "\n",
        "#     Fit the model on the batches generated by datagen.flow().z_mean = Dense(128, name='Dec_VAE_VDraw_Mean')(x)\n",
        "#     model.fit_generator(datagen.flow(x_train, y_train,\n",
        "#                                      batch_size=batch_size),\n",
        "#                         epochs=epochs,\n",
        "#                         validation_data=(x_test, y_test),\n",
        "#                         workers=4)\n",
        "\n",
        "# # Save model and weights\n",
        "# if not os.path.isdir(save_dir):\n",
        "#     os.makedirs(save_dir)\n",
        "# model_path = os.path.join(save_dir, model_name)\n",
        "# model.save(model_path)\n",
        "# print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "# # Score trained model.\n",
        "# scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "# print('Test loss:', scores[0])\n",
        "# print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd954a04rC6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, LeakyReLU\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "\n",
        "import warnings\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Input\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Conv2D,UpSampling2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import AveragePooling2D\n",
        "from keras.layers import GlobalAveragePooling2D,Add\n",
        "from keras.layers import GlobalMaxPooling2D\n",
        "from keras.engine.topology import get_source_inputs\n",
        "from keras.utils.layer_utils import convert_all_kernels_in_model\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras import backend as K\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "from keras.preprocessing import image\n",
        "from keras.layers import Input,Add\n",
        "from keras.models import Model\n",
        "import keras.layers as layers\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OBW_-7srC6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def build_model(inp):\n",
        "    img_input=inp\n",
        "    channel_axis=3\n",
        "    bn_axis=3\n",
        "    x = layers.Conv2D(64, (16, 16),\n",
        "                       strides=(16, 16),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='con')(img_input)\n",
        "  # Block 1\n",
        "    x = layers.Conv2D(64, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block1_conv1')(x)\n",
        "    a1=x\n",
        "    x = layers.Conv2D(64, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block1_conv2')(x)\n",
        "    x = layers.concatenate(\n",
        "      [a1,x],\n",
        "      axis=channel_axis,\n",
        "      name='mixed1')\n",
        "    x = BatchNormalization(axis=bn_axis, scale=False)(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "    x =Dropout(0.25)(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = layers.Conv2D(128, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block2_conv1')(x)\n",
        "    a2=x\n",
        "    x = layers.Conv2D(128, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block2_conv2')(x)\n",
        "    x = layers.concatenate(\n",
        "      [a2,x],\n",
        "      axis=channel_axis,\n",
        "      name='mixed2')\n",
        "    x = BatchNormalization(axis=bn_axis, scale=False)(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "    x =Dropout(0.25)(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = layers.Conv2D(256, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block3_conv1')(x)\n",
        "    a3=x\n",
        "    x = layers.Conv2D(256, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block3_conv2')(x)\n",
        "    x = layers.Conv2D(256, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block3_conv3')(x)\n",
        "    x = layers.concatenate(\n",
        "      [a3,x],\n",
        "      axis=channel_axis,\n",
        "      name='mixed3')\n",
        "    x = BatchNormalization(axis=bn_axis, scale=False)(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "    x =Dropout(0.25)(x)\n",
        "\n",
        "    # Block 4\n",
        "    x = layers.Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block4_conv1')(x)\n",
        "    a4=x\n",
        "    x = layers.Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block4_conv2')(x)\n",
        "    x = layers.Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block4_conv3')(x)\n",
        "    x = layers.concatenate(\n",
        "      [a4,x],\n",
        "      axis=channel_axis,\n",
        "      name='mixed4')\n",
        "    x = BatchNormalization(axis=bn_axis, scale=False)(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "    x =Dropout(0.25)(x)\n",
        "\n",
        "    # Block 5\n",
        "    x = layers.Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block5_conv1')(x)\n",
        "    a5=x\n",
        "    x = layers.Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block5_conv2')(x)\n",
        "    x = layers.Conv2D(512, (3, 3),\n",
        "                      activation='relu',\n",
        "                      padding='same',\n",
        "                      name='block5_conv3')(x)\n",
        "    x = layers.concatenate(\n",
        "      [a5,x],\n",
        "      axis=channel_axis,\n",
        "      name='mixed5')\n",
        "    x = BatchNormalization(axis=bn_axis, scale=False)(x)\n",
        "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
        "    x =Dropout(0.25)(x)\n",
        "    x = layers.Flatten(name='flatten')(x)\n",
        "    x = layers.Dense(4096, activation='relu', name='fc1')(x)\n",
        "    x = layers.Dense(4096, activation='relu', name='fc2')(x)\n",
        "    out = layers.Dense(5, activation='softmax', name='predictions')(x)\n",
        "    model=Model(img_input,out)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7odHJylprC6p",
        "colab_type": "code",
        "colab": {},
        "outputId": "817c667a-2f99-4ce3-e186-303a782cbcb4"
      },
      "source": [
        "x=Input(shape=(1600,2400,3))\n",
        "model=build_model(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W1015 18:51:09.359008 139959246776128 deprecation_wrapper.py:119] From /home/mtechcse/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W1015 18:51:09.391681 139959246776128 deprecation_wrapper.py:119] From /home/mtechcse/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W1015 18:51:09.395875 139959246776128 deprecation_wrapper.py:119] From /home/mtechcse/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W1015 18:51:09.438966 139959246776128 deprecation_wrapper.py:119] From /home/mtechcse/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W1015 18:51:09.440145 139959246776128 deprecation_wrapper.py:119] From /home/mtechcse/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W1015 18:51:12.079398 139959246776128 deprecation_wrapper.py:119] From /home/mtechcse/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W1015 18:51:12.143160 139959246776128 deprecation_wrapper.py:119] From /home/mtechcse/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W1015 18:51:12.148252 139959246776128 deprecation.py:506] From /home/mtechcse/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad058flyrC64",
        "colab_type": "code",
        "colab": {},
        "outputId": "a3fcb24d-44a7-4b28-cc5c-82efc89b76e5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 1600, 2400, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "con (Conv2D)                    (None, 100, 150, 64) 49216       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 100, 150, 64) 36928       con[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 100, 150, 64) 36928       block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 100, 150, 128 0           block1_conv1[0][0]               \n",
            "                                                                 block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 100, 150, 128 384         mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block1_pool (MaxPooling2D)      (None, 50, 75, 128)  0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 50, 75, 128)  0           block1_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv1 (Conv2D)           (None, 50, 75, 128)  147584      dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "block2_conv2 (Conv2D)           (None, 50, 75, 128)  147584      block2_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 50, 75, 256)  0           block2_conv1[0][0]               \n",
            "                                                                 block2_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 50, 75, 256)  768         mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 25, 37, 256)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 25, 37, 256)  0           block2_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv1 (Conv2D)           (None, 25, 37, 256)  590080      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv2 (Conv2D)           (None, 25, 37, 256)  590080      block3_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block3_conv3 (Conv2D)           (None, 25, 37, 256)  590080      block3_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 25, 37, 512)  0           block3_conv1[0][0]               \n",
            "                                                                 block3_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 25, 37, 512)  1536        mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 12, 18, 512)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 12, 18, 512)  0           block3_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv1 (Conv2D)           (None, 12, 18, 512)  2359808     dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv2 (Conv2D)           (None, 12, 18, 512)  2359808     block4_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block4_conv3 (Conv2D)           (None, 12, 18, 512)  2359808     block4_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 12, 18, 1024) 0           block4_conv1[0][0]               \n",
            "                                                                 block4_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 12, 18, 1024) 3072        mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 6, 9, 1024)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 6, 9, 1024)   0           block4_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv1 (Conv2D)           (None, 6, 9, 512)    4719104     dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv2 (Conv2D)           (None, 6, 9, 512)    2359808     block5_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block5_conv3 (Conv2D)           (None, 6, 9, 512)    2359808     block5_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 6, 9, 1024)   0           block5_conv1[0][0]               \n",
            "                                                                 block5_conv3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 6, 9, 1024)   3072        mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block5_pool (MaxPooling2D)      (None, 3, 4, 1024)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 3, 4, 1024)   0           block5_pool[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 12288)        0           dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fc1 (Dense)                     (None, 4096)         50335744    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "fc2 (Dense)                     (None, 4096)         16781312    fc1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Dense)             (None, 5)            20485       fc2[0][0]                        \n",
            "==================================================================================================\n",
            "Total params: 85,852,997\n",
            "Trainable params: 85,847,109\n",
            "Non-trainable params: 5,888\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6U-q31NbrC7C",
        "colab_type": "code",
        "colab": {},
        "outputId": "e2168637-8256-444f-bb73-a53a2cdd7c70"
      },
      "source": [
        "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1015 18:51:24.603755 139959246776128 deprecation_wrapper.py:119] From /home/mtechcse/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ua_vxTLrC7M",
        "colab_type": "code",
        "colab": {},
        "outputId": "26f549ce-3728-497a-89e1-15c31798171e"
      },
      "source": [
        "# model.fit_generator(datagen.flow(x_train, y_train,\n",
        "#                                      batch_size=batch_size),\n",
        "#                         epochs=epochs,\n",
        "#                         steps_per_epoch=115,\n",
        "#                         validation_data=(x_test, y_test),\n",
        "#                         workers=4)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1015 18:51:26.911546 139959246776128 deprecation.py:323] From /home/mtechcse/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "115/115 [==============================] - 877s 8s/step - loss: 8560138456.3530 - acc: 0.4837 - val_loss: 7954620662.9319 - val_acc: 0.5341\n",
            "Epoch 2/100\n",
            "115/115 [==============================] - 820s 7s/step - loss: 1524219729.2384 - acc: 0.6136 - val_loss: 1293435794.1362 - val_acc: 0.5926\n",
            "Epoch 3/100\n",
            "115/115 [==============================] - 834s 7s/step - loss: 1029284132.8258 - acc: 0.6731 - val_loss: 1122777125.4932 - val_acc: 0.7180\n",
            "Epoch 4/100\n",
            "115/115 [==============================] - 820s 7s/step - loss: 924647502.1149 - acc: 0.6965 - val_loss: 971070219.3351 - val_acc: 0.7330\n",
            "Epoch 5/100\n",
            "115/115 [==============================] - 828s 7s/step - loss: 889545849.8323 - acc: 0.7090 - val_loss: 971734329.5477 - val_acc: 0.6975\n",
            "Epoch 6/100\n",
            "115/115 [==============================] - 821s 7s/step - loss: 889932415.6976 - acc: 0.7114 - val_loss: 950109798.7139 - val_acc: 0.6948\n",
            "Epoch 7/100\n",
            "115/115 [==============================] - 835s 7s/step - loss: 851889934.4027 - acc: 0.7166 - val_loss: 843729778.2234 - val_acc: 0.7439\n",
            "Epoch 8/100\n",
            "115/115 [==============================] - 811s 7s/step - loss: 890058342.0641 - acc: 0.7136 - val_loss: 1069681887.7384 - val_acc: 0.7139\n",
            "Epoch 9/100\n",
            "115/115 [==============================] - 832s 7s/step - loss: 851889329.6528 - acc: 0.7220 - val_loss: 986814064.6540 - val_acc: 0.7044\n",
            "Epoch 10/100\n",
            "115/115 [==============================] - 833s 7s/step - loss: 818438044.3668 - acc: 0.7231 - val_loss: 1143081285.4060 - val_acc: 0.6921\n",
            "Epoch 11/100\n",
            "115/115 [==============================] - 825s 7s/step - loss: 822014974.1123 - acc: 0.7204 - val_loss: 852726949.3188 - val_acc: 0.7248\n",
            "Epoch 12/100\n",
            "115/115 [==============================] - 816s 7s/step - loss: 833004140.8131 - acc: 0.7277 - val_loss: 896745141.8856 - val_acc: 0.7262\n",
            "Epoch 13/100\n",
            "115/115 [==============================] - 827s 7s/step - loss: 787239495.2784 - acc: 0.7315 - val_loss: 849109196.3815 - val_acc: 0.7262\n",
            "Epoch 14/100\n",
            "115/115 [==============================] - 834s 7s/step - loss: 794683329.8419 - acc: 0.7326 - val_loss: 1244478006.0599 - val_acc: 0.6553\n",
            "Epoch 15/100\n",
            "115/115 [==============================] - 828s 7s/step - loss: 774146859.4127 - acc: 0.7408 - val_loss: 893356986.4196 - val_acc: 0.7112\n",
            "Epoch 16/100\n",
            "115/115 [==============================] - 816s 7s/step - loss: 770315492.8094 - acc: 0.7427 - val_loss: 786329131.2480 - val_acc: 0.7384\n",
            "Epoch 17/100\n",
            "115/115 [==============================] - 827s 7s/step - loss: 750496633.6744 - acc: 0.7476 - val_loss: 901201707.9455 - val_acc: 0.7289\n",
            "Epoch 18/100\n",
            "115/115 [==============================] - 832s 7s/step - loss: 758098260.6692 - acc: 0.7459 - val_loss: 790364479.4768 - val_acc: 0.7466\n",
            "Epoch 19/100\n",
            "115/115 [==============================] - 830s 7s/step - loss: 727500246.8110 - acc: 0.7519 - val_loss: 1115171825.5259 - val_acc: 0.7139\n",
            "Epoch 20/100\n",
            "115/115 [==============================] - 811s 7s/step - loss: 722787658.0593 - acc: 0.7505 - val_loss: 855678751.7384 - val_acc: 0.7371\n",
            "Epoch 21/100\n",
            "115/115 [==============================] - 829s 7s/step - loss: 715594659.7049 - acc: 0.7598 - val_loss: 861189828.1853 - val_acc: 0.7357\n",
            "Epoch 22/100\n",
            "115/115 [==============================] - 825s 7s/step - loss: 701244630.6592 - acc: 0.7592 - val_loss: 832448312.6757 - val_acc: 0.7439\n",
            "Epoch 23/100\n",
            "115/115 [==============================] - 826s 7s/step - loss: 682424623.3941 - acc: 0.7620 - val_loss: 819550826.3760 - val_acc: 0.7221\n",
            "Epoch 24/100\n",
            "115/115 [==============================] - 816s 7s/step - loss: 704661644.8857 - acc: 0.7715 - val_loss: 881478891.9455 - val_acc: 0.7289\n",
            "Epoch 25/100\n",
            "115/115 [==============================] - 826s 7s/step - loss: 678306206.7375 - acc: 0.7647 - val_loss: 745557106.7466 - val_acc: 0.7480\n",
            "Epoch 26/100\n",
            "115/115 [==============================] - 828s 7s/step - loss: 648493818.1985 - acc: 0.7774 - val_loss: 1135591673.3733 - val_acc: 0.6635\n",
            "Epoch 27/100\n",
            "115/115 [==============================] - 824s 7s/step - loss: 651411041.4757 - acc: 0.7720 - val_loss: 1112157107.9673 - val_acc: 0.7398\n",
            "Epoch 28/100\n",
            "115/115 [==============================] - 818s 7s/step - loss: 664573101.7544 - acc: 0.7723 - val_loss: 887129041.9619 - val_acc: 0.7520\n",
            "Epoch 29/100\n",
            "115/115 [==============================] - 830s 7s/step - loss: 623285400.3228 - acc: 0.7826 - val_loss: 759468257.3951 - val_acc: 0.7602\n",
            "Epoch 30/100\n",
            "115/115 [==============================] - 826s 7s/step - loss: 641511110.2991 - acc: 0.7853 - val_loss: 665411553.1335 - val_acc: 0.7711\n",
            "Epoch 31/100\n",
            "115/115 [==============================] - 831s 7s/step - loss: 617288639.9121 - acc: 0.7870 - val_loss: 675599853.8638 - val_acc: 0.7834\n",
            "Epoch 32/100\n",
            "115/115 [==============================] - 818s 7s/step - loss: 592186006.7296 - acc: 0.7940 - val_loss: 810317194.8120 - val_acc: 0.7766\n",
            "Epoch 33/100\n",
            "115/115 [==============================] - 825s 7s/step - loss: 603573026.0364 - acc: 0.7921 - val_loss: 764172764.4251 - val_acc: 0.7507\n",
            "Epoch 34/100\n",
            "115/115 [==============================] - 833s 7s/step - loss: 571817340.7402 - acc: 0.8022 - val_loss: 752334809.8093 - val_acc: 0.7779\n",
            "Epoch 35/100\n",
            "115/115 [==============================] - 833s 7s/step - loss: 596804301.8365 - acc: 0.7946 - val_loss: 1060356612.8828 - val_acc: 0.7330\n",
            "Epoch 36/100\n",
            "115/115 [==============================] - 817s 7s/step - loss: 583925380.5408 - acc: 0.7997 - val_loss: 872841255.9346 - val_acc: 0.7561\n",
            "Epoch 37/100\n",
            "115/115 [==============================] - 828s 7s/step - loss: 556671890.5439 - acc: 0.8111 - val_loss: 749691582.6049 - val_acc: 0.7548\n",
            "Epoch 38/100\n",
            "115/115 [==============================] - 828s 7s/step - loss: 564275447.2947 - acc: 0.8003 - val_loss: 688778471.0627 - val_acc: 0.7752\n",
            "Epoch 39/100\n",
            "115/115 [==============================] - 828s 7s/step - loss: 571944068.5921 - acc: 0.8003 - val_loss: 1024822209.9183 - val_acc: 0.7330\n",
            "Epoch 40/100\n",
            "115/115 [==============================] - 814s 7s/step - loss: 556652383.7641 - acc: 0.8098 - val_loss: 656753403.2916 - val_acc: 0.7956\n",
            "Epoch 41/100\n",
            "115/115 [==============================] - 824s 7s/step - loss: 556774835.4489 - acc: 0.8141 - val_loss: 1057680170.5504 - val_acc: 0.7371\n",
            "Epoch 42/100\n",
            "115/115 [==============================] - 831s 7s/step - loss: 537268898.5056 - acc: 0.8136 - val_loss: 719394733.6022 - val_acc: 0.8052\n",
            "Epoch 43/100\n",
            "115/115 [==============================] - 825s 7s/step - loss: 545978569.0432 - acc: 0.8076 - val_loss: 707612562.9210 - val_acc: 0.7929\n",
            "Epoch 44/100\n",
            "115/115 [==============================] - 813s 7s/step - loss: 532925816.2456 - acc: 0.8177 - val_loss: 1146415861.7112 - val_acc: 0.7629\n",
            "Epoch 45/100\n",
            "115/115 [==============================] - 833s 7s/step - loss: 525528173.8539 - acc: 0.8231 - val_loss: 960244788.8392 - val_acc: 0.7044\n",
            "Epoch 46/100\n",
            "115/115 [==============================] - 829s 7s/step - loss: 493708253.2125 - acc: 0.8307 - val_loss: 1171289066.8120 - val_acc: 0.7466\n",
            "Epoch 47/100\n",
            "115/115 [==============================] - 831s 7s/step - loss: 525526722.0997 - acc: 0.8114 - val_loss: 633304327.5858 - val_acc: 0.7956\n",
            "Epoch 48/100\n",
            "115/115 [==============================] - 811s 7s/step - loss: 537139168.0230 - acc: 0.8147 - val_loss: 728176233.3297 - val_acc: 0.7902\n",
            "Epoch 49/100\n",
            "115/115 [==============================] - 829s 7s/step - loss: 507979212.2771 - acc: 0.8177 - val_loss: 742012672.6104 - val_acc: 0.7779\n",
            "Epoch 50/100\n",
            "115/115 [==============================] - 830s 7s/step - loss: 487710655.9084 - acc: 0.8253 - val_loss: 842883431.4114 - val_acc: 0.7480\n",
            "Epoch 51/100\n",
            "115/115 [==============================] - 829s 7s/step - loss: 478988805.8931 - acc: 0.8342 - val_loss: 777570328.2398 - val_acc: 0.7602\n",
            "Epoch 52/100\n",
            "115/115 [==============================] - 820s 7s/step - loss: 578775163.5160 - acc: 0.8269 - val_loss: 758357151.7384 - val_acc: 0.7956\n",
            "Epoch 53/100\n",
            "115/115 [==============================] - 829s 7s/step - loss: 470800731.1863 - acc: 0.8334 - val_loss: 885211895.4550 - val_acc: 0.7807\n",
            "Epoch 54/100\n",
            "115/115 [==============================] - 828s 7s/step - loss: 469285901.5937 - acc: 0.8312 - val_loss: 707356331.0736 - val_acc: 0.7779\n",
            "Epoch 55/100\n",
            "115/115 [==============================] - 831s 7s/step - loss: 490785605.5197 - acc: 0.8383 - val_loss: 815530321.1771 - val_acc: 0.7997\n",
            "Epoch 56/100\n",
            "115/115 [==============================] - 819s 7s/step - loss: 517359776.6981 - acc: 0.8402 - val_loss: 694025893.6676 - val_acc: 0.7766\n",
            "Epoch 57/100\n",
            "115/115 [==============================] - 830s 7s/step - loss: 469902417.2329 - acc: 0.8391 - val_loss: 791627462.9755 - val_acc: 0.7589\n",
            "Epoch 58/100\n",
            "115/115 [==============================] - 825s 7s/step - loss: 465760792.8420 - acc: 0.8394 - val_loss: 702817272.7629 - val_acc: 0.7847\n",
            "Epoch 59/100\n",
            "115/115 [==============================] - 825s 7s/step - loss: 446108797.7389 - acc: 0.8500 - val_loss: 985266742.5831 - val_acc: 0.7861\n",
            "Epoch 60/100\n",
            "115/115 [==============================] - 825s 7s/step - loss: 453776971.5687 - acc: 0.8429 - val_loss: 1048858681.2861 - val_acc: 0.7820\n",
            "Epoch 61/100\n",
            "115/115 [==============================] - 828s 7s/step - loss: 474613590.5839 - acc: 0.8435 - val_loss: 901427776.0000 - val_acc: 0.7520\n",
            "Epoch 62/100\n",
            "115/115 [==============================] - 831s 7s/step - loss: 424970551.1802 - acc: 0.8565 - val_loss: 783283098.6812 - val_acc: 0.7834\n",
            "Epoch 63/100\n",
            "115/115 [==============================] - 824s 7s/step - loss: 444520608.9920 - acc: 0.8535 - val_loss: 746863110.2779 - val_acc: 0.8065\n",
            "Epoch 64/100\n",
            "115/115 [==============================] - 823s 7s/step - loss: 467205362.9861 - acc: 0.8516 - val_loss: 872409341.5586 - val_acc: 0.7916\n",
            "Epoch 65/100\n",
            "115/115 [==============================] - 831s 7s/step - loss: 427746787.1224 - acc: 0.8576 - val_loss: 827631281.1771 - val_acc: 0.7820\n",
            "Epoch 66/100\n",
            "115/115 [==============================] - 831s 7s/step - loss: 418755283.2893 - acc: 0.8614 - val_loss: 802441225.9401 - val_acc: 0.7956\n",
            "Epoch 67/100\n",
            "115/115 [==============================] - 827s 7s/step - loss: 388200062.7496 - acc: 0.8671 - val_loss: 909425410.0926 - val_acc: 0.7520\n",
            "Epoch 68/100\n",
            "115/115 [==============================] - 819s 7s/step - loss: 416978907.9268 - acc: 0.8614 - val_loss: 911542312.8065 - val_acc: 0.7670\n",
            "Epoch 69/100\n",
            "115/115 [==============================] - 828s 7s/step - loss: 420763972.8637 - acc: 0.8571 - val_loss: 1090464584.1962 - val_acc: 0.7602\n",
            "Epoch 70/100\n",
            "115/115 [==============================] - 830s 7s/step - loss: 397051459.4582 - acc: 0.8658 - val_loss: 788362715.3787 - val_acc: 0.7766\n",
            "Epoch 71/100\n",
            "115/115 [==============================] - 830s 7s/step - loss: 388333506.5484 - acc: 0.8663 - val_loss: 799171407.8692 - val_acc: 0.7875\n",
            "Epoch 72/100\n",
            "115/115 [==============================] - 815s 7s/step - loss: 390138882.7272 - acc: 0.8671 - val_loss: 1035196386.0054 - val_acc: 0.7725\n",
            "Epoch 73/100\n",
            "115/115 [==============================] - 829s 7s/step - loss: 385623869.5582 - acc: 0.8698 - val_loss: 819371633.7003 - val_acc: 0.7698\n",
            "Epoch 74/100\n",
            "115/115 [==============================] - 836s 7s/step - loss: 341848334.8339 - acc: 0.8772 - val_loss: 1026430197.1880 - val_acc: 0.7738\n",
            "Epoch 75/100\n",
            "115/115 [==============================] - 824s 7s/step - loss: 362625787.9958 - acc: 0.8799 - val_loss: 899802789.6676 - val_acc: 0.8106\n",
            "Epoch 76/100\n",
            "115/115 [==============================] - 818s 7s/step - loss: 372949929.0926 - acc: 0.8766 - val_loss: 956325004.7302 - val_acc: 0.7902\n",
            "Epoch 77/100\n",
            "115/115 [==============================] - 833s 7s/step - loss: 355062051.8913 - acc: 0.8813 - val_loss: 857649987.4877 - val_acc: 0.7875\n",
            "Epoch 78/100\n",
            "115/115 [==============================] - 828s 7s/step - loss: 337156762.5858 - acc: 0.8848 - val_loss: 930202212.0981 - val_acc: 0.7725\n",
            "Epoch 79/100\n",
            "115/115 [==============================] - 828s 7s/step - loss: 345575514.9444 - acc: 0.8813 - val_loss: 895217204.3161 - val_acc: 0.7629\n",
            "Epoch 80/100\n",
            "115/115 [==============================] - 818s 7s/step - loss: 332329990.1806 - acc: 0.8861 - val_loss: 853864797.8202 - val_acc: 0.8106\n",
            "Epoch 81/100\n",
            "115/115 [==============================] - 831s 7s/step - loss: 321643986.0018 - acc: 0.8913 - val_loss: 1247092727.9782 - val_acc: 0.7766\n",
            "Epoch 82/100\n",
            "115/115 [==============================] - 832s 7s/step - loss: 368107723.8437 - acc: 0.8897 - val_loss: 1099514127.1717 - val_acc: 0.8188\n",
            "Epoch 83/100\n",
            "115/115 [==============================] - 825s 7s/step - loss: 351727234.5255 - acc: 0.8826 - val_loss: 1374544561.5259 - val_acc: 0.7725\n",
            "Epoch 84/100\n",
            "115/115 [==============================] - 818s 7s/step - loss: 323036893.6056 - acc: 0.8908 - val_loss: 1202817109.1008 - val_acc: 0.7752\n",
            "Epoch 85/100\n",
            "115/115 [==============================] - 834s 7s/step - loss: 319479085.7089 - acc: 0.9038 - val_loss: 1061843329.7439 - val_acc: 0.8038\n",
            "Epoch 86/100\n",
            "115/115 [==============================] - 829s 7s/step - loss: 329116050.8800 - acc: 0.8878 - val_loss: 855250158.3869 - val_acc: 0.7888\n",
            "Epoch 87/100\n",
            "115/115 [==============================] - 833s 7s/step - loss: 305865006.0510 - acc: 0.9054 - val_loss: 1020601798.9755 - val_acc: 0.7834\n",
            "Epoch 88/100\n",
            "115/115 [==============================] - 812s 7s/step - loss: 310055483.4812 - acc: 0.8948 - val_loss: 918800327.8474 - val_acc: 0.7670\n",
            "Epoch 89/100\n",
            "115/115 [==============================] - 836s 7s/step - loss: 281552302.4900 - acc: 0.9122 - val_loss: 986484705.4823 - val_acc: 0.7602\n",
            "Epoch 90/100\n",
            "115/115 [==============================] - 824s 7s/step - loss: 295265402.9181 - acc: 0.9005 - val_loss: 1087793482.9864 - val_acc: 0.7916\n",
            "Epoch 91/100\n",
            "115/115 [==============================] - 834s 7s/step - loss: 303106235.0509 - acc: 0.9033 - val_loss: 1220067792.3924 - val_acc: 0.7847\n",
            "Epoch 92/100\n",
            "115/115 [==============================] - 816s 7s/step - loss: 341742604.6307 - acc: 0.8997 - val_loss: 779617658.5940 - val_acc: 0.8079\n",
            "Epoch 93/100\n",
            "115/115 [==============================] - 829s 7s/step - loss: 291029089.7949 - acc: 0.9087 - val_loss: 1629353575.2371 - val_acc: 0.7875\n",
            "Epoch 94/100\n",
            "115/115 [==============================] - 836s 7s/step - loss: 295398655.9298 - acc: 0.9033 - val_loss: 1085200929.1335 - val_acc: 0.7807\n",
            "Epoch 95/100\n",
            "115/115 [==============================] - 825s 7s/step - loss: 271759860.4278 - acc: 0.9109 - val_loss: 1047229726.6921 - val_acc: 0.7670\n",
            "Epoch 96/100\n",
            "115/115 [==============================] - 818s 7s/step - loss: 280849820.8783 - acc: 0.9130 - val_loss: 934299111.5858 - val_acc: 0.8025\n",
            "Epoch 97/100\n",
            "115/115 [==============================] - 836s 7s/step - loss: 274705908.6112 - acc: 0.9101 - val_loss: 997206261.8856 - val_acc: 0.7738\n",
            "Epoch 98/100\n",
            "115/115 [==============================] - 827s 7s/step - loss: 259485805.1745 - acc: 0.9179 - val_loss: 925735309.9510 - val_acc: 0.8065\n",
            "Epoch 99/100\n",
            "115/115 [==============================] - 831s 7s/step - loss: 252930367.6114 - acc: 0.9204 - val_loss: 1173573435.1172 - val_acc: 0.7929\n",
            "Epoch 100/100\n",
            "115/115 [==============================] - 819s 7s/step - loss: 278807764.0472 - acc: 0.9144 - val_loss: 1140884630.6703 - val_acc: 0.8025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f18c8648ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zps1acXSrC7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights('retinopathy_w1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNt3JMsarC7l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6345f8f2-f953-4e1d-963c-e1eb0688316b"
      },
      "source": [
        "import cv2\n",
        "ad= cv2.imread('0a2b5e1a0be8.png')\n",
        "ad.shape"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(480, 640, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai_o4T9trC71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy import ndimage\n",
        "result = ndimage.zoom(ad, (1600/480,2400/640,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KK6THlAsspm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result1=result.reshape(1,1600,2400,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvuvevgDszjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans=model.predict(result1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD-2XdnvrC7-",
        "colab_type": "code",
        "colab": {},
        "outputId": "c4522a9a-e8f9-4bd8-cd74-6d45a35dcb35"
      },
      "source": [
        "print(ans)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4.0259116e-04 5.6259274e-01 4.3644065e-01 9.7089668e-08 5.6389719e-04]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIBh_A_jrC8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}